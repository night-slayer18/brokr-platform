server:
  port: 8080
  compression:
    enabled: true
    mime-types: application/json,application/graphql+json,text/html,text/xml,text/plain,application/javascript,text/css
    min-response-size: 1024

spring:
  application:
    name: brokr-platform

  datasource:
    url: ${SPRING_DATASOURCE_URL:jdbc:postgresql://localhost:5432/brokr}
    username: ${SPRING_DATASOURCE_USERNAME:postgres}
    password: ${SPRING_DATASOURCE_PASSWORD:password}
    driver-class-name: org.postgresql.Driver
    hikari:
      # Connection pool configuration
      minimum-idle: 10
      maximum-pool-size: 50  # Increased for concurrent metrics collection and queries
      connection-timeout: 30000
      idle-timeout: 600000
      max-lifetime: 1800000
      leak-detection-threshold: 60000
      # Performance optimizations
      register-mbeans: true  # Enable JMX monitoring
      pool-name: BrokrHikariPool

  jpa:
    hibernate:
      ddl-auto: validate
    show-sql: false
    properties:
      hibernate:
        dialect: org.hibernate.dialect.PostgreSQLDialect
        format_sql: true
        # Batch insert configuration
        jdbc:
          batch_size: 100  # Increased for better throughput with large datasets
          order_inserts: true
          order_updates: true
        # Performance optimizations
        jdbc.batch_versioned_data: true
        # Query optimizations
        query.plan_cache_max_size: 2048
        query.plan_parameter_metadata_max_size: 128

  flyway:
    enabled: true
    locations: classpath:db

  graphql:
    path: /graphql
    graphiql:
      enabled: true
      path: /graphiql

  # Cache configuration
  cache:
    type: caffeine
    caffeine:
      spec: maximumSize=5000,expireAfterWrite=5m,expireAfterAccess=2m
    cache-names:
      - kafkaMessages
      - topicMetrics
      - consumerGroupMetrics
      - clusterMetrics
      - rateLimitConfigs


jwt:
  secret: ${JWT_SECRET:XB0922J6WcWbXAgtFvmmebkfQUVMcjOqX4oag/xEHNY5E1MTFLQ2KSbqL52fmoGLHYCkkkJfzmGBB4vn6yYHlA==}
  expiration: ${JWT_EXPIRATION:86400}

# Security Configuration
security:
  password:
    bcrypt:
      # BCrypt strength (rounds). Higher values are more secure but slower.
      # Recommended: 10-12 for most applications, 13-15 for high-security environments
      # Note: Each increment doubles the computation time
      strength: ${BCRYPT_STRENGTH:10}

# MFA Configuration
mfa:
  encryption:
    # Base64-encoded AES-256 key (32 bytes = 256 bits) for encrypting TOTP secret keys
    # Generate with: openssl rand -base64 32
    # 
    # ⚠️ SECURITY WARNING: 
    # - This is a DEVELOPMENT-ONLY default key
    # - In PRODUCTION: MUST override via environment variable MFA_ENCRYPTION_KEY
    # - NEVER use this default key in production environments
    # - Generate a new key for production: openssl rand -base64 32
    #
    # To override in production:
    #   export MFA_ENCRYPTION_KEY=$(openssl rand -base64 32)
    key: ${MFA_ENCRYPTION_KEY:toIUKBWfqdYUG+2COEOSzH88vXYmqTfJPpkwthZOwxA=}
  totp:
    issuer: ${MFA_TOTP_ISSUER:Brokr Platform}
  backup-codes:
    count: ${MFA_BACKUP_CODES_COUNT:10}
    length: ${MFA_BACKUP_CODES_LENGTH:8}
  rate-limit:
    # Rate limiting for MFA verification attempts to prevent brute force attacks
    max-attempts: ${MFA_RATE_LIMIT_MAX_ATTEMPTS:5}  # Max failed attempts before lockout
    window-minutes: ${MFA_RATE_LIMIT_WINDOW_MINUTES:15}  # Time window for counting attempts
    lockout-minutes: ${MFA_RATE_LIMIT_LOCKOUT_MINUTES:30}  # Lockout duration after max attempts

# Message Replay Configuration
message-replay:
  max-messages-per-job: ${MESSAGE_REPLAY_MAX_MESSAGES:10000000}  # 10 million messages per job (safety limit)
  max-concurrent-jobs: ${MESSAGE_REPLAY_MAX_CONCURRENT:5}  # Maximum concurrent replay jobs
  progress-update-interval: ${MESSAGE_REPLAY_PROGRESS_INTERVAL:1000}  # Update progress every N messages (reduces DB load)
  job-timeout-minutes: ${MESSAGE_REPLAY_TIMEOUT_MINUTES:1440}  # 24 hours timeout
  streaming-batch-size: ${MESSAGE_REPLAY_STREAMING_BATCH:10000}  # Batch size for streaming (prevents OOM)
  rate-limit-messages-per-second: ${MESSAGE_REPLAY_RATE_LIMIT:0}  # 0 = no rate limit (optional throttling)

# API Key Configuration
api-key:
  prefix: ${API_KEY_PREFIX:brokr_}
  secret-length: ${API_KEY_SECRET_LENGTH:32}
  default-expiration-days: ${API_KEY_DEFAULT_EXPIRATION_DAYS:365}
  rotation-grace-period-days: ${API_KEY_ROTATION_GRACE_PERIOD_DAYS:7}
  
  rate-limit:
    default:
      per-second: ${API_KEY_RATE_LIMIT_PER_SECOND:10}
      per-minute: ${API_KEY_RATE_LIMIT_PER_MINUTE:100}
      per-hour: ${API_KEY_RATE_LIMIT_PER_HOUR:1000}
      per-day: ${API_KEY_RATE_LIMIT_PER_DAY:10000}
  
  usage-tracking:
    enabled: ${API_KEY_USAGE_TRACKING_ENABLED:true}
    batch-size: ${API_KEY_USAGE_BATCH_SIZE:100}
    batch-interval-seconds: ${API_KEY_USAGE_BATCH_INTERVAL:5}
    retention-days: ${API_KEY_USAGE_RETENTION_DAYS:90}
  
  security:
    brute-force-protection:
      enabled: ${API_KEY_BRUTE_FORCE_PROTECTION_ENABLED:true}
      max-attempts: ${API_KEY_BRUTE_FORCE_MAX_ATTEMPTS:5}
      lockout-duration-minutes: ${API_KEY_BRUTE_FORCE_LOCKOUT_MINUTES:15}
    suspicious-activity:
      enabled: ${API_KEY_SUSPICIOUS_ACTIVITY_ENABLED:true}
      spike-threshold: ${API_KEY_SUSPICIOUS_SPIKE_THRESHOLD:10}  # 10x normal usage
      new-ip-alert: ${API_KEY_SUSPICIOUS_NEW_IP_ALERT:true}

logging:
  level:
    root: ${LOGGING_LEVEL_ROOT:INFO}
    io.brokr: ${LOGGING_LEVEL_IO_BROKR:DEBUG}
    io.brokr.kafka.service.KafkaConsumerService: ${LOGGING_LEVEL_IO_BROKR_KAFKA_SERVICE_KAFKACONSUMERSERVICE:DEBUG}
    org.springframework.graphql: ${LOGGING_LEVEL_ORG_SPRINGFRAMEWORK_GRAPHQL:DEBUG}
    org.apache.kafka: ${LOGGING_LEVEL_ORG_APACHE_KAFKA:DEBUG}